{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# NOVA — Modelo Ultra Optimizado v4  \n",
        "### LightGBM + XGBoost + CatBoost (Ensemble)\n",
        "\n",
        "En este notebook implementamos un modelo de *Machine Learning* de tipo **ensemble heterogéneo**, combinando tres algoritmos del estado del arte:\n",
        "\n",
        "- **LightGBM**\n",
        "- **XGBoost**\n",
        "- **CatBoost**\n",
        "\n",
        "El objetivo es predecir el desempeño de los estudiantes en la variable:\n",
        "\n"
      ],
      "metadata": {
        "id": "69syjylNem0m"
      },
      "id": "69syjylNem0m"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Este pipeline incluye:\n",
        "\n",
        "1. Descarga automática del dataset desde Kaggle  \n",
        "2. Preprocesamiento completo de variables numéricas y categóricas  \n",
        "3. Entrenamiento de tres modelos independientes  \n",
        "4. Blending (ensemble ponderado) con pesos optimizados  \n",
        "5. Generación del archivo `submission.csv`  \n",
        "6. Envío automático a Kaggle\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "jIHE51ioexFQ"
      },
      "id": "jIHE51ioexFQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4d8ba70",
      "metadata": {
        "id": "a4d8ba70"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Descarga de datos desde Kaggle\n",
        "# ================================================================================\n",
        "\n",
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '.'\n",
        "!chmod 600 ./kaggle.json\n",
        "!kaggle competitions download -c udea-ai-4-eng-20252-pruebas-saber-pro-colombia\n",
        "!unzip udea*.zip > /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalación de librerías necesarias\n",
        "\n",
        "Algunos algoritmos utilizados (CatBoost, LightGBM, XGBoost) no vienen preinstalados en todos los entornos de ejecución.\n",
        "\n",
        "En esta celda instalamos:\n",
        "\n",
        "- **CatBoost** → Excelente para variables categóricas\n",
        "- **LightGBM** → Modelo rápido y eficiente basado en árboles\n",
        "- **XGBoost** → Modelo robusto para predicción tabular\n",
        "\n",
        "Luego podremos importarlos sin errores.\n"
      ],
      "metadata": {
        "id": "88hwZDmme_qI"
      },
      "id": "88hwZDmme_qI"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "id": "IQ8VoAKXd1nc"
      },
      "id": "IQ8VoAKXd1nc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e1bbb4df",
      "metadata": {
        "id": "e1bbb4df"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "#     NOVA — MODELO ULTRA OPTIMIZADO v4 (LightGBM + XGBoost + CatBoost)\n",
        "# ================================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carga de datos y limpieza inicial\n",
        "\n",
        "En esta sección:\n",
        "\n",
        "- Cargamos los archivos `train.csv` y `test.csv`.\n",
        "- Eliminamos columnas duplicadas generadas por Pandas (las que terminan en `.1`).\n",
        "- Creamos una copia segura del dataset para evitar modificaciones no deseadas.\n",
        "\n",
        "También preparamos la variable objetivo:\n"
      ],
      "metadata": {
        "id": "0p8ocn8-fGtb"
      },
      "id": "0p8ocn8-fGtb"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "3d33fb22",
      "metadata": {
        "id": "3d33fb22"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# 1. Cargar datos\n",
        "# ================================================================================\n",
        "\n",
        "train = pd.read_csv(\"train.csv\")\n",
        "test  = pd.read_csv(\"test.csv\")\n",
        "\n",
        "target = \"RENDIMIENTO_GLOBAL\"\n",
        "\n",
        "# Quitar columnas duplicadas tipo *.1\n",
        "dups = [c for c in train.columns if \".1\" in c]\n",
        "train = train.drop(columns=dups, errors=\"ignore\")\n",
        "test  = test.drop(columns=dups, errors=\"ignore\")\n",
        "\n",
        "# Copia segura\n",
        "df = train.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocesamiento: Manejo de NaN y codificación de variables\n",
        "\n",
        "Este paso es fundamental para el correcto entrenamiento de los modelos:\n",
        "\n",
        "### 1. Identificación de columnas categóricas  \n",
        "Detectamos todas las columnas tipo `object`.\n",
        "\n",
        "### 2. CatBoost no acepta valores NaN  \n",
        "→ Los reemplazamos por `\"MISSING\"`.\n",
        "\n",
        "### 3. Valores numéricos faltantes  \n",
        "→ Se reemplazan por un valor sentinela seguro (`-9999`).\n",
        "\n",
        "### 4. Conversión final a tipo `category`  \n",
        "LightGBM aprovecha esta conversión para acelerar el entrenamiento.\n",
        "\n",
        "### 5. Codificación del target  \n",
        "Convertimos la variable objetivo a valores numéricos con `LabelEncoder`.\n",
        "\n",
        "Este preprocesamiento permite que los tres modelos trabajen con los tipos de datos adecuados.\n"
      ],
      "metadata": {
        "id": "E5DmxOsufjMG"
      },
      "id": "E5DmxOsufjMG"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "6862d45a",
      "metadata": {
        "id": "6862d45a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cda76e40-93eb-4def-9b3b-ef7d1796d783"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Categorías detectadas: 13\n"
          ]
        }
      ],
      "source": [
        "# ================================================================================\n",
        "# 2. Preprocesamiento: categorizar columnas y limpiar NaN\n",
        "# ================================================================================\n",
        "\n",
        "categorical_cols = []\n",
        "\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == object and col != target:\n",
        "        categorical_cols.append(col)\n",
        "\n",
        "# ---- FIX: CatBoost no acepta NaN -> convertir a string ----\n",
        "for col in categorical_cols:\n",
        "    df[col] = df[col].astype(\"object\").fillna(\"MISSING\")\n",
        "    if col in test.columns:\n",
        "        test[col] = test[col].astype(\"object\").fillna(\"MISSING\")\n",
        "\n",
        "# ---- FIX: NaN numéricos -> sentinel value seguro ----\n",
        "for col in df.columns:\n",
        "    if df[col].dtype != object and col != target:\n",
        "        df[col] = df[col].fillna(-9999)\n",
        "        if col in test.columns:\n",
        "            test[col] = test[col].fillna(-9999)\n",
        "\n",
        "# Convertir finalmente a categoría\n",
        "for col in categorical_cols:\n",
        "    df[col] = df[col].astype(\"category\")\n",
        "    if col in test.columns:\n",
        "        test[col] = test[col].astype(\"category\")\n",
        "\n",
        "print(f\"Categorías detectadas: {len(categorical_cols)}\")\n",
        "\n",
        "# Codificar target\n",
        "le = LabelEncoder()\n",
        "df[target] = le.fit_transform(df[target])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# División Train / Validation\n",
        "\n",
        "Dividimos el dataset en:\n",
        "\n",
        "- **85%** para entrenamiento  \n",
        "- **15%** para validación\n",
        "\n",
        "Usamos división *estratificada* para mantener la proporción real de clases en ambos conjuntos.\n",
        "\n",
        "Esto es crucial para obtener métricas confiables sin sesgo.\n"
      ],
      "metadata": {
        "id": "SMmH-_dIfsuL"
      },
      "id": "SMmH-_dIfsuL"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c1c727be",
      "metadata": {
        "id": "c1c727be"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# 3. Train / Validation split\n",
        "# ================================================================================\n",
        "\n",
        "X = df.drop(columns=[target])\n",
        "y = df[target]\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.15, random_state=42, stratify=y\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo 1 — LightGBM\n",
        "\n",
        "LightGBM es un algoritmo basado en gradient boosting muy rápido y eficiente.\n",
        "\n",
        "En este paso:\n",
        "\n",
        "- Entrenamos un modelo multiclase\n",
        "- Indicamos las columnas categóricas para aceleración\n",
        "- Calculamos la precisión (accuracy) en el conjunto de validación\n",
        "\n",
        "LightGBM suele aprender bien en datasets con muchas variables categóricas.\n"
      ],
      "metadata": {
        "id": "P4aOvsYOfwk-"
      },
      "id": "P4aOvsYOfwk-"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "db6ff35c",
      "metadata": {
        "id": "db6ff35c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6589f553-1f1d-486a-b009-b8bd2b9f509e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Entrenando LightGBM...\n",
            "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
            "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.154660 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1887\n",
            "[LightGBM] [Info] Number of data points in the train set: 588625, number of used features: 19\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            " LightGBM Accuracy: 0.4406\n"
          ]
        }
      ],
      "source": [
        "# ================================================================================\n",
        "# 4. MODEL 1 — LIGHTGBM\n",
        "# ================================================================================\n",
        "\n",
        "print(\"\\nEntrenando LightGBM...\")\n",
        "\n",
        "lgb_model = lgb.LGBMClassifier(\n",
        "    n_estimators=600,\n",
        "    learning_rate=0.03,\n",
        "    num_leaves=45,\n",
        "    max_depth=9,\n",
        "    min_child_samples=15,\n",
        "    subsample=0.9,\n",
        "    colsample_bytree=0.9,\n",
        "    reg_alpha=1.3,\n",
        "    reg_lambda=2.5,\n",
        "    objective=\"multiclass\",\n",
        "    class_weight=\"balanced\",\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "lgb_model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    categorical_feature=categorical_cols\n",
        ")\n",
        "\n",
        "lgb_val_pred = lgb_model.predict(X_val)\n",
        "lgb_acc = accuracy_score(y_val, lgb_val_pred)\n",
        "\n",
        "print(f\" LightGBM Accuracy: {lgb_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo 2 — XGBoost\n",
        "\n",
        "XGBoost requiere que las categorías estén **codificadas como números**, por eso convertimos y luego:\n",
        "\n",
        "- Entrenamos el modelo usando `hist`, que acelera el entrenamiento\n",
        "- Evaluamos su precisión en el conjunto de validación\n",
        "\n",
        "XGBoost es robusto y suele generalizar muy bien en datos tabulares.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "X-e5P1KPgWaT"
      },
      "id": "X-e5P1KPgWaT"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "491d8abd",
      "metadata": {
        "id": "491d8abd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "263bd3fb-95cf-470f-ca6d-e1140703b0d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Entrenando XGBoost...\n",
            " XGBoost Accuracy: 0.4349\n"
          ]
        }
      ],
      "source": [
        "# ================================================================================\n",
        "# 5. MODEL 2 — XGBOOST\n",
        "# ================================================================================\n",
        "\n",
        "print(\"\\nEntrenando XGBoost...\")\n",
        "\n",
        "# Convertir categorías -> códigos\n",
        "X_train_xgb = X_train.copy()\n",
        "X_val_xgb   = X_val.copy()\n",
        "test_xgb    = test.copy()\n",
        "\n",
        "for col in X_train_xgb.columns:\n",
        "    if str(X_train_xgb[col].dtype) in [\"category\", \"object\"]:\n",
        "        X_train_xgb[col] = X_train_xgb[col].astype(\"category\").cat.codes\n",
        "        X_val_xgb[col]   = X_val_xgb[col].astype(\"category\").cat.codes\n",
        "        test_xgb[col]    = test_xgb[col].astype(\"category\").cat.codes\n",
        "\n",
        "xgb_model = xgb.XGBClassifier(\n",
        "    n_estimators=550,\n",
        "    learning_rate=0.035,\n",
        "    max_depth=8,\n",
        "    subsample=0.85,\n",
        "    colsample_bytree=0.85,\n",
        "    min_child_weight=3,\n",
        "    reg_alpha=1.2,\n",
        "    reg_lambda=3.0,\n",
        "    gamma=0.2,\n",
        "    objective=\"multi:softprob\",\n",
        "    eval_metric=\"mlogloss\",\n",
        "    tree_method=\"hist\",\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "xgb_model.fit(X_train_xgb, y_train)\n",
        "xgb_val_pred = xgb_model.predict(X_val_xgb)\n",
        "\n",
        "xgb_acc = accuracy_score(y_val, xgb_val_pred)\n",
        "\n",
        "print(f\" XGBoost Accuracy: {xgb_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo 3 — CatBoost\n",
        "\n",
        "CatBoost está especialmente diseñado para manejar variables categóricas **sin necesidad de codificación manual**.\n",
        "\n",
        "En este paso:\n",
        "\n",
        "- Se entrenan 300 iteraciones\n",
        "- Se usa validación interna con `eval_set`\n",
        "- Se obtiene la precisión en el conjunto de validación\n",
        "\n",
        "CatBoost suele ser el modelo que mejor captura relaciones complejas en las categorías.\n"
      ],
      "metadata": {
        "id": "M2fUb5RFgrA4"
      },
      "id": "M2fUb5RFgrA4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3b1c132",
      "metadata": {
        "id": "e3b1c132",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3e8d8a8-3909-49bc-e574-fda47925e655"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Entrenando CatBoost...\n"
          ]
        }
      ],
      "source": [
        "# ================================================================================\n",
        "# 6. MODEL 3 — CATBOOST\n",
        "# ================================================================================\n",
        "\n",
        "print(\"\\nEntrenando CatBoost...\")\n",
        "\n",
        "cat_model = CatBoostClassifier(\n",
        "    iterations=300,\n",
        "    learning_rate=0.06,\n",
        "    depth=6,\n",
        "    l2_leaf_reg=3,\n",
        "    loss_function=\"MultiClass\",\n",
        "    random_seed=42,\n",
        "    task_type=\"CPU\",\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "cat_model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    cat_features=categorical_cols,\n",
        "    eval_set=(X_val, y_val),\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "cat_val_pred = cat_model.predict(X_val).flatten().astype(int)\n",
        "cat_acc = accuracy_score(y_val, cat_val_pred)\n",
        "\n",
        "print(f\" CatBoost Accuracy: {cat_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ensemble final — Blending ponderado\n",
        "\n",
        "Combinamos las probabilidades de los tres modelos:\n",
        "\n",
        "- `w_lgb = 0.55`\n",
        "- `w_xgb = 0.20`\n",
        "- `w_cat = 0.25`\n",
        "\n",
        "El ensemble se calcula:\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bQXUo97lgwwT"
      },
      "id": "bQXUo97lgwwT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a911290",
      "metadata": {
        "id": "1a911290"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# 7. ENSEMBLE (BLENDING)\n",
        "# ================================================================================\n",
        "\n",
        "print(\"\\nCalculando Ensemble final...\")\n",
        "\n",
        "lgb_p = lgb_model.predict_proba(X_val)\n",
        "xgb_p = xgb_model.predict_proba(X_val_xgb)\n",
        "cat_p = cat_model.predict_proba(X_val)\n",
        "\n",
        "w_lgb = 0.55\n",
        "w_xgb = 0.20\n",
        "w_cat = 0.25\n",
        "\n",
        "blend = (w_lgb*lgb_p) + (w_xgb*xgb_p) + (w_cat*cat_p)\n",
        "blend_pred = np.argmax(blend, axis=1)\n",
        "\n",
        "blend_acc = accuracy_score(y_val, blend_pred)\n",
        "print(f\" Ensemble Accuracy: {blend_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalmente:\n",
        "\n",
        "- Se selecciona la clase con máxima probabilidad\n",
        "- Se calcula la precisión final del ensemble\n",
        "\n",
        "En general, el ensemble supera el rendimiento individual de cada modelo.\n",
        "\n",
        "# Generación del archivo de submission\n",
        "\n",
        "Con el ensemble final:\n",
        "\n",
        "- Predecimos los valores del archivo `test.csv`\n",
        "- Invertimos el Label Encoding para recuperar los nombres originales de las clases\n",
        "- Creamos el archivo `my_submission.csv`\n",
        "\n",
        "Este archivo es el que enviamos a Kaggle para evaluar nuestro desempeño en el leaderboard."
      ],
      "metadata": {
        "id": "ucLvGAnshGPb"
      },
      "id": "ucLvGAnshGPb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1529ae4",
      "metadata": {
        "id": "d1529ae4"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# 8. PREDICCIÓN FINAL SOBRE TEST\n",
        "# ================================================================================\n",
        "\n",
        "print(\"Generando predicciones finales...\\n\")\n",
        "\n",
        "lgb_test = lgb_model.predict_proba(test)\n",
        "xgb_test = xgb_model.predict_proba(test_xgb)\n",
        "cat_test = cat_model.predict_proba(test)\n",
        "\n",
        "final_blend = (w_lgb*lgb_test) + (w_xgb*xgb_test) + (w_cat*cat_test)\n",
        "final_pred = np.argmax(final_blend, axis=1)\n",
        "\n",
        "final_labels = le.inverse_transform(final_pred)\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    \"ID\": test[\"ID\"],\n",
        "    \"RENDIMIENTO_GLOBAL\": final_labels\n",
        "})\n",
        "\n",
        "submission.to_csv(\"my_submission.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Envío automático a Kaggle\n",
        "\n",
        "En esta última celda:\n",
        "\n",
        "1. Configuramos la API de Kaggle  \n",
        "2. Enviamos el archivo `my_submission.csv` directamente a la competencia  \n",
        "3. Registramos el envío con un mensaje descriptivo\n",
        "\n",
        "Esto automatiza completamente el ciclo:\n",
        "**entrenar → predecir → generar submission → enviar a Kaggle**."
      ],
      "metadata": {
        "id": "3o7w5FeMhYyk"
      },
      "id": "3o7w5FeMhYyk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7955a5c1",
      "metadata": {
        "id": "7955a5c1"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Envío del submission a Kaggle\n",
        "# ================================================================================\n",
        "\n",
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '.'\n",
        "!chmod 600 ./kaggle.json\n",
        "\n",
        "!kaggle competitions submit -c udea-ai-4-eng-20252-pruebas-saber-pro-colombia \\\n",
        "-f my_submission.csv -m \"Entrega version final - Equipo Juan y Jose\""
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}